<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Real-Time Translator</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 15px;
      background: #f2f6ff;
      margin: 0;
    }

    h1 {
      font-size: 1.8rem;
      margin-bottom: 10px;
    }

    select, button {
      font-size: 1rem;
      padding: 12px;
      margin: 8px;
      border-radius: 10px;
      border: none;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    select {
      background: white;
      width: 90%;
      max-width: 350px;
    }

    button {
      background: #007BFF;
      color: white;
      width: 90%;
      max-width: 350px;
      cursor: pointer;
      transition: 0.2s;
    }

    button:active {
      transform: scale(0.97);
    }

    button:disabled {
      background: gray;
      cursor: not-allowed;
    }

    #translations, #liveText {
      margin-top: 20px;
      text-align: left;
      max-width: 500px;
      margin-left: auto;
      margin-right: auto;
      background: white;
      padding: 15px;
      border-radius: 10px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }

    #translations {
      max-height: 250px; 
      overflow-y: auto;
    }

    .chunk {
      padding: 5px 40px 5px 5px;
      margin-bottom: 8px;
      border-radius: 5px;
      background-color: #e0f7fa;
      position: relative;
      font-size: 1rem;
      word-wrap: break-word;
    }

    .replayBtn {
      position: absolute;
      right: 5px;
      top: 50%;
      transform: translateY(-50%);
      background: #007BFF;
      color: white;
      border: none;
      border-radius: 5px;
      padding: 3px 7px;
      cursor: pointer;
      font-size: 0.9rem;
    }

    #liveText {
      font-style: italic;
      color: #333;
      font-size: 1rem;
    }

    @media (max-width: 600px) {
      h1 {
        font-size: 1.5rem;
      }
      select, button {
        font-size: 1rem;
      }
      #translations, #liveText {
        width: 95%;
      }
    }
  </style>
</head>
<body>
  <h1>üåç Real-Time Translator</h1>
  <p>Select your languages and tap Start:</p>

  <label for="fromLang">üé§ Input Language:</label><br>
  <select id="fromLang">
    <option value="en">English</option>
    <option value="es">Spanish</option>
    <option value="sv">Swedish</option>
    <option value="fr">French</option>
  </select><br>

  <label for="toLang">üîä Output Language:</label><br>
  <select id="toLang">
    <option value="en">English</option>
    <option value="es">Spanish</option>
    <option value="sv">Swedish</option>
    <option value="fr">French</option>
  </select><br>

  <button id="toggleBtn">‚ñ∂ Allow Microphone & Start</button>

  <div id="liveText">üéôÔ∏è Live text will appear here...</div>
  <div id="translations"></div>

  <script>
    const toggleBtn = document.getElementById("toggleBtn");
    const translationsDiv = document.getElementById("translations");
    const liveText = document.getElementById("liveText");
    const fromLang = document.getElementById("fromLang");
    const toLang = document.getElementById("toLang");
    const langMap = { "es": "es-ES", "en": "en-US", "sv": "sv-SE", "fr": "fr-FR" };

    let recognition;
    let isListening = false;
    let currentTranscript = "";
    let lastSpeechTime = 0;
    let ttsAllowed = false;

    // Ask for audio playback permission on tap
    async function requestPlaybackPermission() {
      return new Promise(resolve => {
        const audio = new Audio();
        audio.src = "data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABAAZGF0YQAAAAA="; // silent sound
        audio.play()
          .then(() => {
            ttsAllowed = true;
            resolve(true);
          })
          .catch(() => {
            alert("Tap the screen to allow sound playback.");
            resolve(false);
          });
      });
    }

    // Ask for mic permission before starting
    async function requestMicPermission() {
      try {
        await navigator.mediaDevices.getUserMedia({ audio: true });
        return true;
      } catch {
        alert("Microphone access is required for speech recognition.");
        return false;
      }
    }

    if ("webkitSpeechRecognition" in window) {
      recognition = new webkitSpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onresult = (event) => {
        let interimTranscript = "";
        let finalTranscript = "";
        const now = Date.now();

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = (event.results[i][0].transcript || "").trim();
          if (event.results[i].isFinal) {
            finalTranscript += transcript + " ";
          } else {
            interimTranscript += transcript + " ";
          }
        }

        if (interimTranscript) {
          liveText.textContent = "üéôÔ∏è " + interimTranscript;
          currentTranscript = interimTranscript;
          lastSpeechTime = now;
        }

        if (finalTranscript) {
          liveText.textContent = "üéôÔ∏è " + finalTranscript;
          currentTranscript = finalTranscript;
          commitChunk();
        }

        if (lastSpeechTime && now - lastSpeechTime > 300) {
          commitChunk();
        }
      };

      recognition.onerror = (e) => console.warn("Recognition error:", e);
    } else {
      alert("Speech Recognition not supported in this browser.");
    }

    async function commitChunk() {
      const transcript = currentTranscript.trim();
      if (!transcript) return;

      currentTranscript = "";
      lastSpeechTime = 0;
      liveText.textContent = "üéôÔ∏è ‚Ä¶";

      const from = fromLang.value;
      const to = toLang.value;

      if (from === to) {
        addTranslation(transcript, transcript);
        speak(transcript, langMap[to]);
        return;
      }

      fetch(`https://api.mymemory.translated.net/get?q=${encodeURIComponent(transcript)}&langpair=${from}|${to}`)
        .then(res => res.json())
        .then(data => {
          const translated = data?.responseData?.translatedText || "(translation failed)";
          addTranslation(transcript, translated);
          speak(translated, langMap[to]);
        })
        .catch(() => addTranslation(transcript, "(translation failed)"));
    }

    function addTranslation(original, translated) {
      const chunkDiv = document.createElement("div");
      chunkDiv.className = "chunk";
      chunkDiv.innerHTML = `<strong>${original}</strong> ‚Üí ${translated}`;
      const replayBtn = document.createElement("button");
      replayBtn.textContent = "üîä";
      replayBtn.className = "replayBtn";
      replayBtn.onclick = () => speak(translated, langMap[toLang.value]);
      chunkDiv.appendChild(replayBtn);

      translationsDiv.appendChild(chunkDiv);
      translationsDiv.scrollTop = translationsDiv.scrollHeight;
    }

    function speak(text, langCode) {
      if (!ttsAllowed) return; // don't play until permission granted
      const utterance = new SpeechSynthesisUtterance(text);
      const voices = speechSynthesis.getVoices();
      const match = voices.find(v => v.lang.startsWith(langCode));
      if (match) utterance.voice = match;
      utterance.lang = langCode;
      speechSynthesis.speak(utterance);
    }

    toggleBtn.addEventListener("click", async () => {
      if (!isListening) {
        const micAllowed = await requestMicPermission();
        const soundAllowed = await requestPlaybackPermission();
        if (!micAllowed || !soundAllowed) return;

        recognition.lang = langMap[fromLang.value];
        recognition.start();
        isListening = true;
        toggleBtn.textContent = "‚èπ Stop";
        toggleBtn.style.background = "#dc3545";
      } else {
        recognition.stop();
        isListening = false;
        toggleBtn.textContent = "‚ñ∂ Start";
        toggleBtn.style.background = "#007BFF";
        commitChunk();
      }
    });

    window.speechSynthesis.onvoiceschanged = () => {};
  </script>
</body>
</html>
