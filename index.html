<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Real-Time Translator ‚Äî Full</title>
<style>
  :root{
    --blue:#007BFF;
    --accent:#0b84e6;
    --bg:#f6fbff;
    --panel:#f1fbff;
    --card:#eaf9ff;
    --muted:#6b7280;
    --radius:12px;
  }
  html,body{height:100%}
  body{
    margin:0;padding:20px;background:var(--bg);font-family:Inter,Segoe UI,Helvetica,Arial,sans-serif;color:#0b1724;
  }
  .wrap{max-width:820px;margin:0 auto}
  h1{margin:6px 0 12px;text-align:center;font-weight:600}
  .controls{display:flex;flex-wrap:wrap;gap:10px;align-items:center;justify-content:center;margin-bottom:14px}
  label{font-size:14px;color:#0b1724}
  select,button{padding:10px 14px;border-radius:10px;border:1px solid rgba(11,24,36,0.08);font-size:15px}
  button{background:var(--blue);color:#fff;cursor:pointer}
  button.secondary{background:var(--accent)}
  button.ghost{background:#fff;color:var(--blue);border:1px solid rgba(11,24,36,0.06)}
  button:disabled{background:gray;cursor:not-allowed}
  .status{background:#fff;padding:12px;border-radius:12px;border:1px solid #e6eef7;margin-bottom:12px;min-height:56px;display:flex;align-items:center}
  .status .text{font-style:italic;color:#334155}
  #translations{max-height:430px;overflow:auto;padding:8px}
  .chunk{background:var(--card);padding:12px;border-radius:12px;margin:10px 0;position:relative;border-left:6px solid var(--blue);box-shadow:0 6px 18px rgba(15,23,42,0.04)}
  .chunk strong{display:block;font-size:16px;margin-bottom:8px}
  .chunk .translated{color:#0b1724}
  .replayBtn{position:absolute;right:10px;top:50%;transform:translateY(-50%);border:none;padding:8px;border-radius:10px;background:var(--blue);color:#fff;cursor:pointer}
  .controls-group{display:flex;gap:8px;flex-wrap:wrap;align-items:center}
  footer{margin-top:10px;text-align:center;color:var(--muted);font-size:13px}
  @media (max-width:520px){
    .controls{flex-direction:column}
    .controls-group{width:100%;justify-content:center}
  }
</style>
</head>
<body>
<div class="wrap">
  <h1>Real-Time Translator</h1>

  <div class="controls" role="toolbar" aria-label="controls">
    <div style="display:flex;gap:6px;align-items:center">
      <label for="fromLang" style="margin-right:6px">Input:</label>
      <select id="fromLang" aria-label="Input language">
        <option value="en-US">English</option>
        <option value="es-ES">Spanish</option>
        <option value="fr-FR">French</option>
        <option value="de-DE">German</option>
        <option value="sv-SE">Swedish</option>
      </select>
    </div>

    <div style="display:flex;gap:6px;align-items:center">
      <label for="toLang" style="margin-right:6px">Output:</label>
      <select id="toLang" aria-label="Output language">
        <option value="en">English</option>
        <option value="es">Spanish</option>
        <option value="fr">French</option>
        <option value="de">German</option>
        <option value="sv">Swedish</option>
      </select>
    </div>

    <div class="controls-group" style="margin-left:6px">
      <button id="enableAudioBtn" class="ghost" title="Enable audio">Enable Audio</button>
      <button id="toggleBtn" title="Start/Stop recognition">Start</button>
      <button id="replayAllBtn" class="secondary" title="Replay all translations">Replay All</button>
      <button id="clearBtn" class="secondary" title="Clear all translations">Clear All</button>
    </div>
  </div>

  <div class="status" role="status" aria-live="polite">
    <div class="text" id="liveText">üéôÔ∏è Live text will appear here...</div>
  </div>

  <div id="translations" aria-live="polite"></div>

  <footer>Uses Web Speech (webkitSpeechRecognition) + MyMemory translator (demo). For best results use Chrome on Android or Safari on iOS.</footer>
</div>

<script>
/*
  Full feature translator:
  - Android/Samsung fixes: continuous=true, controlled interim handling, newline cleanup, duplicate protection
  - Per-chunk replay and Replay All
  - Enable Audio button (TTS unlock)
  - Robust commit logic with silence timer and final-only safety
  - Uses MyMemory free API for demo (replaceable)
*/

const enableAudioBtn = document.getElementById('enableAudioBtn');
const toggleBtn = document.getElementById('toggleBtn');
const replayAllBtn = document.getElementById('replayAllBtn');
const clearBtn = document.getElementById('clearBtn');
const translationsDiv = document.getElementById('translations');
const liveText = document.getElementById('liveText');
const fromLang = document.getElementById('fromLang');
const toLang = document.getElementById('toLang');

// Map for selecting TTS voices (best-effort matching)
const langSpeechMap = { "es":"es-ES", "en":"en-US", "fr":"fr-FR", "de":"de-DE", "sv":"sv-SE" };

let recognition = null;
let listening = false;
let audioEnabled = false;

let interimBuffer = "";            // latest interim text
let lastCommittedFinal = "";       // last final committed (prevents duplicates)
let silenceTimer = null;           // timer for pause-based commit
let allTranslations = [];          // history for replay all

// Helper: simple HTML escape for safe insertion
function escapeHtml(s) {
  return String(s).replace(/[&<>"']/g, function(m){
    return {'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[m];
  });
}

// Enable audio (required gesture on some mobile)
enableAudioBtn.addEventListener('click', () => {
  try {
    const u = new SpeechSynthesisUtterance("Audio enabled");
    speechSynthesis.speak(u);
    audioEnabled = true;
    enableAudioBtn.disabled = true;
    enableAudioBtn.textContent = "Audio Enabled";
    enableAudioBtn.classList.remove('ghost');
  } catch (e) {
    console.warn('TTS enable failed', e);
  }
});

// Speak helper: tries to match voice by lang code prefix
function speak(text, langCode) {
  if (!audioEnabled) return;
  try {
    const ut = new SpeechSynthesisUtterance(text);
    const voices = speechSynthesis.getVoices() || [];
    const prefix = (langCode||'').split('-')[0];
    // preference: exact match then startsWith
    let voice = voices.find(v => v.lang === langCode) || voices.find(v => v.lang && v.lang.startsWith(prefix));
    if (voice) ut.voice = voice;
    ut.lang = langCode || 'en-US';
    speechSynthesis.speak(ut);
  } catch (e) {
    console.warn('TTS error', e);
  }
}

// Add translation entry to UI (and attach per-chunk replay)
function addTranslation(original, translated) {
  const div = document.createElement('div');
  div.className = 'chunk';
  div.innerHTML = `<strong>${escapeHtml(original)}</strong><div class="translated">‚Üí ${escapeHtml(translated)}</div>`;

  const btn = document.createElement('button');
  btn.className = 'replayBtn';
  btn.title = 'Play translation';
  btn.innerText = 'üîä';
  btn.onclick = () => speak(translated, langSpeechMap[toLang.value] || toLang.value);

  div.appendChild(btn);
  translationsDiv.prepend(div);

  allTranslations.push(translated);
}

// Translate via MyMemory (demo). Pair is en|fr style using language root codes.
async function translateText(text, fromCode, toCode) {
  try {
    const q = encodeURIComponent(text);
    const fromRoot = (fromCode || 'en').split('-')[0];
    const toRoot = (toCode || 'en').split('-')[0];
    // MyMemory expects langpair like en|fr
    const url = `https://api.mymemory.translated.net/get?q=${q}&langpair=${fromRoot}|${toRoot}`;
    const res = await fetch(url);
    const json = await res.json();
    return (json && json.responseData && json.responseData.translatedText) ? json.responseData.translatedText : '(translation failed)';
  } catch (e) {
    console.warn('translate error', e);
    return '(translation failed)';
  }
}

// Clean transcript: remove newline artifacts and HTML entities that appear in Android outputs
function cleanTranscript(t) {
  if (!t) return '';
  // Replace HTML newline entity and newline characters with spaces; collapse whitespace
  return t.replace(/(&#10;|\r\n|\n|\r)/g, ' ').replace(/\s+/g, ' ').trim();
}

// Commit a chunk: translate + add to UI + optional TTS
async function commitChunk(text) {
  const cleaned = cleanTranscript(text);
  if (!cleaned) return;
  if (cleaned === lastCommittedFinal) return; // skip duplicates

  lastCommittedFinal = cleaned;
  const from = fromLang.value || 'en-US';
  const to = toLang.value || 'en';

  const translated = await translateText(cleaned, from, to);
  addTranslation(cleaned, translated);
  if (audioEnabled) speak(translated, langSpeechMap[to] || to);
}

// Initialize recognition instance with robust handlers (Android-friendly)
function initRecognition() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) {
    alert('Speech recognition not supported in this browser.');
    return null;
  }

  const r = new SpeechRecognition();
  r.continuous = true;           // required for Android to keep streaming
  r.interimResults = true;       // we will use interim to show live text, but commit carefully
  r.lang = fromLang.value || 'en-US';

  // A debounce/pause-based commit: on interim, start/reset timer
  const PAUSE_MS = 1000; // 1s pause to auto-commit interim if final doesn't arrive

  r.onresult = (event) => {
    // Clear any previous pause timer when new data arrives
    if (silenceTimer) {
      clearTimeout(silenceTimer);
      silenceTimer = null;
    }

    // Combine results from latest event (some Android builds emit multiple finals)
    let interimText = '';
    let foundFinals = [];

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const res = event.results[i];
      const txt = (res[0] && res[0].transcript) ? res[0].transcript.trim() : '';
      if (!txt) continue;
      if (res.isFinal) {
        foundFinals.push(txt);
      } else {
        interimText = txt; // keep latest interim
      }
    }

    // If any final segments arrived, combine them into a single final string and commit once
    if (foundFinals.length > 0) {
      const combined = foundFinals.join(' ');
      const cleaned = cleanTranscript(combined);
      liveText.textContent = 'üéôÔ∏è ' + cleaned;
      // Commit final immediately (and avoid duplicates)
      commitChunk(cleaned);
      interimBuffer = '';
    } else if (interimText) {
      // No final yet ‚Äî show interim and set silence timer to commit as fallback
      interimBuffer = interimText;
      liveText.textContent = 'üéôÔ∏è ' + cleanTranscript(interimText);

      // If no final arrives in PAUSE_MS, commit the interim as a chunk (useful on Android mobile)
      silenceTimer = setTimeout(() => {
        silenceTimer = null;
        if (interimBuffer) {
          const fallback = cleanTranscript(interimBuffer);
          if (fallback && fallback !== lastCommittedFinal) {
            commitChunk(fallback);
          }
          interimBuffer = '';
        }
      }, PAUSE_MS);
    }
  };

  r.onerror = (e) => {
    console.warn('recognition error', e);
  };

  // Some Android builds stop recognition unexpectedly ‚Äî restart when appropriate
  r.onend = () => {
    listening = false;
    toggleBtn.textContent = 'Start';
    // If interim text remained and wasn't committed, commit it once as fallback
    if (interimBuffer && interimBuffer !== lastCommittedFinal) {
      const fallback = cleanTranscript(interimBuffer);
      if (fallback) commitChunk(fallback);
      interimBuffer = '';
    }
    // On Android we may want to auto-restart if the user hasn't explicitly stopped
    // We'll only restart if the toggle indicates we should be listening (prevents loops after explicit stop)
    if (shouldAutoRestart) {
      // A small delay avoids immediate tremor restarts on some devices
      setTimeout(() => {
        try {
          r.start();
          listening = true;
          toggleBtn.textContent = 'Stop';
        } catch (e) {
          console.warn('auto-restart failed', e);
        }
      }, 350);
    }
  };

  return r;
}

// State controlling auto restart behaviour
let shouldAutoRestart = false;

// Start listening
function startListening() {
  if (listening) return;
  // reset last interim only; keep lastCommittedFinal to avoid duplicates
  interimBuffer = '';

  if (!recognition) {
    recognition = initRecognition();
    if (!recognition) return;
  } else {
    // update language in running recognizer if needed
    recognition.lang = fromLang.value || recognition.lang;
  }

  shouldAutoRestart = true;
  try {
    recognition.start();
    listening = true;
    toggleBtn.textContent = 'Stop';
    liveText.textContent = 'üéôÔ∏è Listening...';
  } catch (e) {
    console.warn('start error', e);
  }
}

// Stop listening (user-initiated)
function stopListening() {
  shouldAutoRestart = false;
  if (silenceTimer) {
    clearTimeout(silenceTimer);
    silenceTimer = null;
  }
  if (!recognition) return;
  try {
    recognition.stop();
  } catch (e) {
    console.warn('stop error', e);
  }
  listening = false;
  toggleBtn.textContent = 'Start';
  // commit last interim as fallback
  if (interimBuffer && interimBuffer !== lastCommittedFinal) {
    commitChunk(cleanTranscript(interimBuffer));
    interimBuffer = '';
  }
}

// Toggle button click
toggleBtn.addEventListener('click', () => {
  if (!listening) startListening();
  else stopListening();
});

// Replay all translations sequentially
replayAllBtn.addEventListener('click', () => {
  if (!allTranslations.length) {
    alert('No translations to replay.');
    return;
  }
  // Play earliest first ‚Äî allTranslations holds appended order; we want chronological: last at end
  const queue = allTranslations.slice(); // copy
  queue.forEach((text, i) => {
    setTimeout(() => speak(text, langSpeechMap[toLang.value] || toLang.value), i * 1400);
  });
});

// Clear all translations
clearBtn.addEventListener('click', () => {
  if (!confirm('Clear all translations?')) return;
  translationsDiv.innerHTML = '';
  allTranslations = [];
  lastCommittedFinal = '';
  interimBuffer = '';
  speechSynthesis.cancel();
});

// If language changed mid-listen, restart recognizer to pick up new lang
fromLang.addEventListener('change', () => {
  if (listening) {
    stopListening();
    setTimeout(startListening, 200);
  }
});

// Ensure voices loaded for TTS selection
window.speechSynthesis.onvoiceschanged = () => { /* no-op: just ensure list populates */ };

// Defensive cleanup on unload
window.addEventListener('beforeunload', () => {
  shouldAutoRestart = false;
  try { stopListening(); } catch (e) {}
  try { speechSynthesis.cancel(); } catch (e) {}
});

// Initialize with no active recognition instance (created on start)
recognition = null;
</script>
</body>
</html>
